# RAG_Core/agents/supervisor.py - REMOVED CONTEXT PROCESSOR

from typing import Dict, Any, List
from langchain_core.messages import HumanMessage, SystemMessage
from models.llm_model import llm_model
from tools.vector_search import check_database_connection
import logging
import json
import re

logger = logging.getLogger(__name__)


class SupervisorAgent:
    def __init__(self):
        self.name = "SUPERVISOR"
        self.classification_prompt = """B·∫°n l√† chuy√™n vi√™n ƒë√†o t·∫°o k·ªπ nƒÉng chuy·ªÉn ƒë·ªïi s·ªë, ki·∫øn th·ª©c s·ª≠ d·ª•ng c√¥ng ngh·ªá th√¥ng tin c∆° b·∫£n cho ng∆∞·ªùi d√¢n - ng∆∞·ªùi ƒëi·ªÅu ph·ªëi ch√≠nh c·ªßa h·ªá th·ªëng chatbot.

        Nhi·ªám v·ª•:
        1. D·ª±a v√†o l·ªãch s·ª≠ h·ªôi tho·∫°i v√† c√¢u h·ªèi hi·ªán t·∫°i, h√£y x√°c ƒë·ªãnh ng·ªØ c·∫£nh (context) m√† ng∆∞·ªùi d√πng ƒëang ƒë·ªÅ c·∫≠p ƒë·∫øn.
        2. L√†m r√µ c√¢u h·ªèi n·∫øu c·∫ßn thi·∫øt (thay th·∫ø ƒë·∫°i t·ª´, b·ªï sung th√¥ng tin t·ª´ context).
        3. Ph√¢n lo·∫°i c√¢u h·ªèi v√† ch·ªçn agent ph√π h·ª£p ƒë·ªÉ x·ª≠ l√Ω.

        C√°c agent c√≥ th·ªÉ ch·ªçn:
        - FAQ: D√πng cho ch√†o h·ªèi th√¢n thi·ªán, c√¢u h·ªèi th∆∞·ªùng g·∫∑p, ho·∫∑c c√°c y√™u c·∫ßu li√™n quan ƒë·∫øn ƒë√†o t·∫°o k·ªπ nƒÉng chuy·ªÉn ƒë·ªïi s·ªë cho ng∆∞·ªùi d√¢n v√† doanh nghi·ªáp.
        - OTHER: C√¢u h·ªèi ho·∫∑c y√™u c·∫ßu n·∫±m ngo√†i ph·∫°m vi chuy·ªÉn ƒë·ªïi s·ªë.
        - CHATTER: Ng∆∞·ªùi d√πng c√≥ d·∫•u hi·ªáu kh√¥ng h√†i l√≤ng, gi·∫≠n d·ªØ, ho·∫∑c c·∫ßn ƒë∆∞·ª£c an ·ªßi, l√†m d·ªãu.
        - REPORTER: Khi ng∆∞·ªùi d√πng ph·∫£n √°nh l·ªói, m·∫•t k·∫øt n·ªëi, ho·∫∑c v·∫•n ƒë·ªÅ k·ªπ thu·∫≠t c·ªßa h·ªá th·ªëng.

        ƒê·∫ßu v√†o:
        C√¢u h·ªèi hi·ªán t·∫°i: "{question}"
        L·ªãch s·ª≠ h·ªôi tho·∫°i: {history}
        Tr·∫°ng th√°i h·ªá th·ªëng: {system_status}

        Y√äU C·∫¶U QUAN TR·ªåNG:
        - Ph√¢n t√≠ch xem c√¢u h·ªèi c√≥ ph·∫£i follow-up (ti·∫øp theo cu·ªôc tr√≤ chuy·ªán tr∆∞·ªõc) kh√¥ng
        - N·∫øu l√† follow-up: l√†m r√µ c√¢u h·ªèi b·∫±ng c√°ch thay th·∫ø ƒë·∫°i t·ª´ v√† b·ªï sung th√¥ng tin t·ª´ l·ªãch s·ª≠
        - T·∫°o context_summary B·∫∞NG TI·∫æNG VI·ªÜT t√≥m t·∫Øt ng·∫Øn g·ªçn ng·ªØ c·∫£nh
        - N·∫øu kh√¥ng ph·∫£i follow-up: contextualized_question = c√¢u h·ªèi g·ªëc, context_summary = "C√¢u h·ªèi ƒë·ªôc l·∫≠p"

        H√£y tr·∫£ l·ªùi ƒë√∫ng ƒë·ªãnh d·∫°ng JSON:
        {{
          "is_followup": true ho·∫∑c false,
          "contextualized_question": "C√¢u h·ªèi ƒë√£ ƒë∆∞·ª£c l√†m r√µ (n·∫øu l√† follow-up) ho·∫∑c c√¢u h·ªèi g·ªëc",
          "context_summary": "T√≥m t·∫Øt ng·∫Øn g·ªçn ng·ªØ c·∫£nh B·∫∞NG TI·∫æNG VI·ªÜT",
          "agent": "FAQ" ho·∫∑c "CHATTER" ho·∫∑c "REPORTER" ho·∫∑c "OTHER"
        }}

        V√≠ d·ª•:
        - N·∫øu c√¢u h·ªèi: "N√≥ ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o?" sau khi h·ªèi v·ªÅ "AI l√† g√¨?"
          ‚Üí is_followup: true
          ‚Üí contextualized_question: "AI ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o?"
          ‚Üí context_summary: "Ti·∫øp t·ª•c v·ªÅ ch·ªß ƒë·ªÅ AI"
          ‚Üí agent: "FAQ"

        - N·∫øu c√¢u h·ªèi: "T√¥i c·∫ßn h·ªó tr·ª£ kh·∫©n c·∫•p"
          ‚Üí is_followup: false
          ‚Üí contextualized_question: "T√¥i c·∫ßn h·ªó tr·ª£ kh·∫©n c·∫•p"
          ‚Üí context_summary: "C√¢u h·ªèi ƒë·ªôc l·∫≠p"
          ‚Üí agent: "FAQ"

        Ch·ªâ tr·∫£ v·ªÅ JSON, kh√¥ng th√™m text n√†o kh√°c."""

    def classify_request(
            self,
            question: str,
            history: List[Dict[str, str]] = None
    ) -> Dict[str, Any]:
        """
        Ph√¢n lo·∫°i y√™u c·∫ßu - UPDATED: T·ª± x·ª≠ l√Ω context trong LLM, kh√¥ng d√πng context_processor
        """
        try:
            logger.info("-" * 50)
            logger.info("üë®‚Äçüíº SUPERVISOR CLASSIFICATION")
            logger.info("-" * 50)
            logger.info(f"üìù Question: '{question}'")
            logger.info(f"üìö History Length: {len(history) if history else 0} messages")

            # Ki·ªÉm tra tr·∫°ng th√°i h·ªá th·ªëng
            db_status = check_database_connection.invoke({})

            if not db_status.get("connected", False):
                logger.warning("‚ö†Ô∏è  Database not connected ‚Üí REPORTER")
                return {
                    "agent": "REPORTER",
                    "contextualized_question": question,
                    "context_summary": "H·ªá th·ªëng m·∫•t k·∫øt n·ªëi",
                    "is_followup": False
                }

            # Format l·ªãch s·ª≠
            history_text = self._format_history(history or [])

            # T·∫°o prompt - LLM s·∫Ω t·ª± x·ª≠ l√Ω context
            prompt = self.classification_prompt.format(
                question=question,
                history=history_text,
                system_status="B√¨nh th∆∞·ªùng" if db_status.get("connected") else "L·ªói k·∫øt n·ªëi"
            )

            # G·ªçi LLM ƒë·ªÉ ph√¢n lo·∫°i V√Ä l√†m r√µ context
            logger.info("ü§ñ Calling LLM for classification + contextualization...")
            response = llm_model.invoke(prompt)

            # Parse JSON response
            classification = self._parse_classification_response(response)

            # Extract fields
            agent_choice = classification.get("agent", "").upper()
            is_followup = classification.get("is_followup", False)
            contextualized_question = classification.get("contextualized_question", question)
            context_summary = classification.get("context_summary", "")

            # Validate agent choice
            valid_agents = ["FAQ", "CHATTER", "REPORTER", "OTHER"]
            if agent_choice not in valid_agents:
                logger.warning(f"‚ö†Ô∏è  Invalid agent '{agent_choice}' ‚Üí default to FAQ")
                agent_choice = "FAQ"

            logger.info(f"\nüéØ CLASSIFICATION RESULT:")
            logger.info(f"   Agent: {agent_choice}")
            logger.info(f"   Is Follow-up: {is_followup}")
            logger.info(f"   Original Q: '{question[:60]}'")
            logger.info(f"   Context Q:  '{contextualized_question[:60]}'")
            logger.info(f"   Context Summary: '{context_summary[:80]}'")
            logger.info("-" * 50 + "\n")

            return {
                "agent": agent_choice,
                "contextualized_question": contextualized_question,
                "context_summary": context_summary,
                "is_followup": is_followup,
                "reasoning": classification.get("reasoning", "")
            }

        except Exception as e:
            logger.error(f"‚ùå Error in supervisor classification: {e}", exc_info=True)
            logger.info("‚Ü©Ô∏è  Using default: agent=FAQ, no context")
            return {
                "agent": "FAQ",
                "contextualized_question": question,
                "context_summary": "",
                "is_followup": False,
                "reasoning": "Error - default to FAQ"
            }

    def _parse_classification_response(self, response: str) -> Dict[str, Any]:
        """Parse JSON response t·ª´ LLM"""
        try:
            # T√¨m JSON block trong response
            json_match = re.search(r'\{[^}]+\}', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                parsed = json.loads(json_str)

                # Ensure required fields
                if "is_followup" not in parsed:
                    parsed["is_followup"] = False
                if "contextualized_question" not in parsed:
                    parsed["contextualized_question"] = ""
                if "context_summary" not in parsed:
                    parsed["context_summary"] = ""
                if "agent" not in parsed:
                    parsed["agent"] = "FAQ"

                return parsed

            # Fallback parsing
            return {
                "agent": "FAQ",
                "is_followup": False,
                "contextualized_question": "",
                "context_summary": "",
                "reasoning": "Parse failed"
            }

        except Exception as e:
            logger.error(f"Error parsing classification response: {e}")
            return {
                "agent": "FAQ",
                "is_followup": False,
                "contextualized_question": "",
                "context_summary": "",
                "reasoning": "Parse error"
            }

    def _format_history(self, history: List[Dict[str, str]]) -> str:
        """Format history th√†nh text, x·ª≠ l√Ω c·∫£ dict v√† ChatMessage objects"""
        if not history:
            return "Kh√¥ng c√≥ l·ªãch s·ª≠"

        # Ch·ªâ l·∫•y 3 turn g·∫ßn nh·∫•t (6 messages)
        recent_history = history[-6:] if len(history) > 6 else history

        history_lines = []
        for msg in recent_history:
            # X·ª≠ l√Ω c·∫£ dict v√† ChatMessage object
            if isinstance(msg, dict):
                role = "Ng∆∞·ªùi d√πng" if msg.get("role") == "user" else "Tr·ª£ l√Ω"
                content = msg.get("content", "")[:200]
            else:
                # ChatMessage object
                role = "Ng∆∞·ªùi d√πng" if getattr(msg, "role", "") == "user" else "Tr·ª£ l√Ω"
                content = getattr(msg, "content", "")[:200]

            if content:
                history_lines.append(f"{role}: {content}")

        return "\n".join(history_lines) if history_lines else "Kh√¥ng c√≥ l·ªãch s·ª≠"