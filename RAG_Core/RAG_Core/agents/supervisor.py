# RAG_Core/agents/supervisor.py

from typing import Dict, Any, List
from langchain_core.messages import HumanMessage, SystemMessage
from models.llm_model import llm_model
from tools.vector_search import check_database_connection
from utils.context_processor import context_processor
import logging
import json
import re

logger = logging.getLogger(__name__)


class SupervisorAgent:
    def __init__(self):
        self.name = "SUPERVISOR"
        self.classification_prompt = """B·∫°n l√† chuy√™n vi√™n ƒë√†o t·∫°o k·ªπ nƒÉng chuy·ªÉn ƒë·ªïi s·ªë, ki·∫øn th·ª©c s·ª≠ d·ª•ng c√¥ng ngh·ªá th√¥ng tin c∆° b·∫£n cho ng∆∞·ªùi d√¢n - ng∆∞·ªùi ƒëi·ªÅu ph·ªëi ch√≠nh c·ªßa h·ªá th·ªëng chatbot.

        Nhi·ªám v·ª•:
        1. D·ª±a v√†o l·ªãch s·ª≠ h·ªôi tho·∫°i v√† c√¢u h·ªèi hi·ªán t·∫°i, h√£y x√°c ƒë·ªãnh ng·ªØ c·∫£nh (context) m√† ng∆∞·ªùi d√πng ƒëang ƒë·ªÅ c·∫≠p ƒë·∫øn.
        2. Ph√¢n lo·∫°i c√¢u h·ªèi v√† ch·ªçn agent ph√π h·ª£p ƒë·ªÉ x·ª≠ l√Ω.

        C√°c agent c√≥ th·ªÉ ch·ªçn:
        - FAQ: D√πng cho ch√†o h·ªèi th√¢n thi·ªán, c√¢u h·ªèi th∆∞·ªùng g·∫∑p, ho·∫∑c c√°c y√™u c·∫ßu li√™n quan ƒë·∫øn ƒë√†o t·∫°o k·ªπ nƒÉng chuy·ªÉn ƒë·ªïi s·ªë cho ng∆∞·ªùi d√¢n v√† doanh nghi·ªáp.
        - OTHER: C√¢u h·ªèi ho·∫∑c y√™u c·∫ßu n·∫±m ngo√†i ph·∫°m vi chuy·ªÉn ƒë·ªïi s·ªë.
        - CHATTER: Ng∆∞·ªùi d√πng c√≥ d·∫•u hi·ªáu kh√¥ng h√†i l√≤ng, gi·∫≠n d·ªØ, ho·∫∑c c·∫ßn ƒë∆∞·ª£c an ·ªßi, l√†m d·ªãu.
        - REPORTER: Khi ng∆∞·ªùi d√πng ph·∫£n √°nh l·ªói, m·∫•t k·∫øt n·ªëi, ho·∫∑c v·∫•n ƒë·ªÅ k·ªπ thu·∫≠t c·ªßa h·ªá th·ªëng.

        ƒê·∫ßu v√†o:
        C√¢u h·ªèi g·ªëc: "{original_question}"
        C√¢u h·ªèi ƒë√£ ƒë∆∞·ª£c l√†m r√µ ng·ªØ c·∫£nh: "{contextualized_question}"
        L·ªãch s·ª≠ h·ªôi tho·∫°i: {history}
        Tr·∫°ng th√°i h·ªá th·ªëng: {system_status}
        C√≥ ph·∫£i follow-up question: {is_followup}
        Context li√™n quan: {relevant_context}

        Y√äU C·∫¶U QUAN TR·ªåNG:
        - B·∫ÆT BU·ªòC tr·∫£ l·ªùi context_summary B·∫∞NG TI·∫æNG VI·ªÜT
        - KH√îNG ƒë∆∞·ª£c d√πng ti·∫øng Anh trong context_summary
        - N·∫øu kh√¥ng c√≥ context, ghi "C√¢u h·ªèi ƒë·ªôc l·∫≠p" ho·∫∑c "Kh√¥ng c√≥ ng·ªØ c·∫£nh"

        H√£y tr·∫£ l·ªùi ƒë√∫ng ƒë·ªãnh d·∫°ng JSON:
        {{
          "context_summary": "T√≥m t·∫Øt ng·∫Øn g·ªçn ng·ªØ c·∫£nh B·∫∞NG TI·∫æNG VI·ªÜT (n·∫øu c√≥)",
          "agent": "FAQ" ho·∫∑c "CHATTER" ho·∫∑c "REPORTER" ho·∫∑c "OTHER"
        }}

        V√≠ d·ª• context_summary h·ª£p l·ªá:
        - "H·ªèi v·ªÅ c√°ch s·ª≠ d·ª•ng AI"
        - "Ti·∫øp t·ª•c v·ªÅ ch·ªß ƒë·ªÅ an to√†n th√¥ng tin"
        - "C√¢u h·ªèi ƒë·ªôc l·∫≠p"
        - "Kh√¥ng c√≥ ng·ªØ c·∫£nh"

        V√≠ d·ª• KH√îNG h·ª£p l·ªá (ƒë·ª´ng l√†m th·∫ø n√†y):
        - "Asking about AI usage"
        - "Follow-up question about security"

        Ch·ªâ tr·∫£ v·ªÅ JSON, kh√¥ng th√™m text n√†o kh√°c."""

    def classify_request(
            self,
            question: str,
            history: List[Dict[str, str]] = None
    ) -> Dict[str, Any]:
        """
        Ph√¢n lo·∫°i y√™u c·∫ßu v√† ch·ªçn agent ph√π h·ª£p

        UPDATED: Better logging for context extraction
        """
        try:
            logger.info("-" * 50)
            logger.info("üë®‚Äçüíº SUPERVISOR CLASSIFICATION")
            logger.info("-" * 50)
            logger.info(f"üìù Original Question: '{question}'")
            logger.info(f"üìö History Length: {len(history) if history else 0} messages")

            # Ki·ªÉm tra tr·∫°ng th√°i h·ªá th·ªëng
            db_status = check_database_connection.invoke({})

            if not db_status.get("connected", False):
                logger.warning("‚ö†Ô∏è  Database not connected ‚Üí REPORTER")
                return {
                    "agent": "REPORTER",
                    "contextualized_question": question,
                    "context_summary": "H·ªá th·ªëng m·∫•t k·∫øt n·ªëi",
                    "is_followup": False
                }

            # X·ª≠ l√Ω context t·ª´ history
            logger.info("üîç Extracting context from history...")

            context_info = context_processor.extract_context_from_history(
                history or [],
                question
            )

            contextualized_question = context_info["contextualized_question"]
            is_followup = context_info["is_followup"]
            relevant_context = context_info["relevant_context"]

            # Log contextualization result
            if is_followup:
                logger.info("‚úÖ FOLLOW-UP QUESTION DETECTED")
                logger.info(f"   Original:      '{question}'")
                logger.info(f"   Contextualized: '{contextualized_question}'")
                logger.info(f"   Context:       {relevant_context[:100]}...")
            else:
                logger.info("üìå STANDALONE QUESTION")
                logger.info(f"   Question: '{contextualized_question}'")

            # N·∫øu LLM kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c ng·ªØ c·∫£nh h·ª£p l·ªá
            if "[c·∫ßn l√†m r√µ]" in contextualized_question:
                logger.info("‚ö†Ô∏è  Context unclear ‚Üí treating as standalone")
                contextualized_question = question
                is_followup = False
                relevant_context = ""

            # Format l·ªãch s·ª≠
            history_text = self._format_history(history or [])

            # T·∫°o prompt
            prompt = self.classification_prompt.format(
                original_question=question,
                contextualized_question=contextualized_question,
                history=history_text,
                system_status="B√¨nh th∆∞·ªùng" if db_status.get("connected") else "L·ªói k·∫øt n·ªëi",
                is_followup="C√≥" if is_followup else "Kh√¥ng",
                relevant_context=relevant_context[:300] if relevant_context else "Kh√¥ng c√≥"
            )

            # G·ªçi LLM ƒë·ªÉ ph√¢n lo·∫°i
            logger.info("ü§ñ Calling LLM for agent classification...")
            response = llm_model.invoke(prompt)

            # Parse JSON response
            classification = self._parse_classification_response(response)

            # Validate agent choice
            valid_agents = ["FAQ", "CHATTER", "REPORTER", "OTHER"]
            agent_choice = classification.get("agent", "").upper()

            if agent_choice not in valid_agents:
                logger.warning(f"‚ö†Ô∏è  Invalid agent '{agent_choice}' ‚Üí fallback classification")
                agent_choice = self._fallback_classify(contextualized_question)

            logger.info(f"\nüéØ CLASSIFICATION RESULT:")
            logger.info(f"   Agent: {agent_choice}")
            logger.info(f"   Is Follow-up: {is_followup}")
            logger.info(f"   Context Summary: {classification.get('context_summary', '')[:100]}")
            logger.info("-" * 50 + "\n")

            return {
                "agent": agent_choice,
                "contextualized_question": contextualized_question,
                "context_summary": classification.get("context_summary", ""),
                "is_followup": is_followup,
                "reasoning": classification.get("reasoning", "")
            }

        except Exception as e:
            logger.error(f"‚ùå Error in supervisor classification: {e}", exc_info=True)
            logger.info("‚Ü©Ô∏è  Using fallback classification")
            return {
                "agent": self._fallback_classify(question),
                "contextualized_question": question,
                "context_summary": "",
                "is_followup": False,
                "reasoning": "Fallback due to error"
            }

    def _parse_classification_response(self, response: str) -> Dict[str, Any]:
        """Parse JSON response t·ª´ LLM"""
        try:
            # T√¨m JSON block trong response
            json_match = re.search(r'\{[^}]+\}', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                return json.loads(json_str)

            # Fallback parsing
            return {
                "agent": "FAQ",
                "context_summary": "",
                "reasoning": "Parse failed"
            }

        except Exception as e:
            logger.error(f"Error parsing classification response: {e}")
            return {
                "agent": "FAQ",
                "context_summary": "",
                "reasoning": "Parse error"
            }

    def _format_history(self, history: List[Dict[str, str]]) -> str:
        """Format history th√†nh text, x·ª≠ l√Ω c·∫£ dict v√† ChatMessage objects"""
        if not history:
            return "Kh√¥ng c√≥ l·ªãch s·ª≠"

        # Ch·ªâ l·∫•y 3 turn g·∫ßn nh·∫•t (6 messages)
        recent_history = history[-6:] if len(history) > 6 else history

        history_lines = []
        for msg in recent_history:
            # X·ª≠ l√Ω c·∫£ dict v√† ChatMessage object
            if isinstance(msg, dict):
                role = "Ng∆∞·ªùi d√πng" if msg.get("role") == "user" else "Tr·ª£ l√Ω"
                content = msg.get("content", "")[:200]
            else:
                # ChatMessage object
                role = "Ng∆∞·ªùi d√πng" if getattr(msg, "role", "") == "user" else "Tr·ª£ l√Ω"
                content = getattr(msg, "content", "")[:200]

            if content:
                history_lines.append(f"{role}: {content}")

        return "\n".join(history_lines) if history_lines else "Kh√¥ng c√≥ l·ªãch s·ª≠"

    def _fallback_classify(self, question: str) -> str:
        """Ph√¢n lo·∫°i d·ª± ph√≤ng d·ª±a tr√™n t·ª´ kh√≥a"""
        question_lower = question.lower()

        # Chatter keywords - c·∫£m x√∫c ti√™u c·ª±c
        chatter_keywords = [
            "t·ªá", "k√©m", "t·ªìi", "kh√¥ng h√†i l√≤ng", "gi·∫≠n",
            "ph·∫£n ƒë·ªëi", "khi·∫øu n·∫°i", "th·∫•t v·ªçng", "t·ª©c gi·∫≠n"
        ]
        if any(keyword in question_lower for keyword in chatter_keywords):
            return "CHATTER"

        # Reporter keywords - l·ªói h·ªá th·ªëng
        reporter_keywords = [
            "l·ªói", "kh√¥ng ho·∫°t ƒë·ªông", "b·ªã l·ªói", "kh√¥ng k·∫øt n·ªëi",
            "kh√¥ng truy c·∫≠p ƒë∆∞·ª£c", "h·ªèng", "kh√¥ng ph·∫£n h·ªìi"
        ]
        if any(keyword in question_lower for keyword in reporter_keywords):
            return "REPORTER"

        # FAQ keywords - c√¢u h·ªèi th√¥ng th∆∞·ªùng
        faq_keywords = [
            "l√† g√¨", "nh∆∞ th·∫ø n√†o", "sao", "t·∫°i sao", "c√≥ ph·∫£i",
            "gi·ªù l√†m vi·ªác", "li√™n h·ªá", "h∆∞·ªõng d·∫´n", "c√°ch", "th·∫ø n√†o"
        ]
        if any(keyword in question_lower for keyword in faq_keywords):
            return "FAQ"

        # Default to FAQ for document search
        return "FAQ"